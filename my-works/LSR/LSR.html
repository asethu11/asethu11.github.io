<!DOCTYPE html>
<html lang="en">
    <head>
        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-98H0ZTK0T4"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag() {
                dataLayer.push(arguments);
            }
            gtag('js', new Date());

            gtag('config', 'G-98H0ZTK0T4');
        </script>

        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <title>User Testing for Safety Messaging</title>
        <meta name="author" content="asethu11">
        <meta name="description" content="Portfolio of Abhishek, a UX Designer based in USA.">
        <meta name="keywords" content="UX, UI, Design, Portfolio, Arizona, USA">
        <meta name="robots" content="index, follow">
        <meta name="theme-color" content="#040404" media="(prefers-color-scheme: dark)">
        <meta name="theme-color" content="#FCFCFC" media="(prefers-color-scheme: light)">

        <script src="script.js"></script>
        <link rel="stylesheet" href="LSR.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
        <link rel="icon" href="/img/favicon.png" type="image/png">

        <script>
            function updateImages() {
            const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches;
            document.querySelectorAll(".theme-img").forEach(img => {
                const imageName = img.dataset.name; // Get the image name
                img.src = isDarkMode ? `darkmode/${imageName}.jpg` : `lightmode/${imageName}.jpg`;
            });
        }
        
        // Run on page load
        updateImages();
        
        // Listen for theme changes
        window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change", updateImages);
        
        </script>

        <script>
            function updateImages() {
                const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches;
                document.querySelectorAll(".theme-img").forEach(img => {
                    const imageName = img.dataset.name; // Get the image name
                    const newSrc = isDarkMode 
                        ? `img/dk/${imageName}.png` 
                        : `img/lt/${imageName}.png`;

                    // Only update if the src has changed (prevents unnecessary reloads)
                    if (img.src !== newSrc) {
                        img.src = newSrc;
                    }
                });
            }

            // Ensure images update on theme change
            const darkModeQuery = window.matchMedia("(prefers-color-scheme: dark)");
            darkModeQuery.addEventListener("change", updateImages);

            // Run on page load
            document.addEventListener("DOMContentLoaded", updateImages);
        </script>
    </head>

    <body>
        <a href="../../index.html" class="back-button">
            <svg width="24" height="24" viewBox="0 0 24 24" fill="none"
                xmlns="http://www.w3.org/2000/svg">
                <path d="M19 12H5M5 12L12 19M5 12L12 5"
                    stroke="currentColor" 
                    stroke-width="2" 
                    stroke-linecap="round"
                    stroke-linejoin="round"/>
            </svg>
            Home
        </a>

        <div class="article-container">
            <article class="article-body">
                
               <!-- Intro Section -->
                <section class="section-1">
                    <div class="grey-background-article image-bottom">
                        <figure class="article-figure">
                            <!-- Image updates based on theme -->
                            <img class="theme-img" src="" data-name="slide1" width="100%" alt="">
                        </figure>
                    </div>

                    <h1 class="article-h1">
                        AI-Powered Data Extraction Interface for Clinical Researchers at MayoClinic
                    </h1>

                    <p>
                        We built an Airtable-style “smart spreadsheet” that lets doctors pull structured clinical trial data
                        from PDFs—fast, transparently, and with full control. The tool blends AI-assisted extraction with human
                        validation, streamlining a previously manual and error-prone workflow into a focused, fluid experience.
                    </p>

                    <div class="sub-header">
                        <p id="intro-tags1">
                             Mar-April 2025 | Product Designer & TL | Web-App
                        </p>
                    </div>
                </section>
                
                <hr><!-------------------------------------------->

                <!-- TL;DR Section -->
                <section class="section-tldr">
                    <h2>TL;DR</h2>
                    <ul>
                        <li><b>Problem:</b> 100+ hrs/review, error-prone manual data extraction.</li>
                        <li><b>Solution:</b> AI-augmented, spreadsheet-style UI with inline evidence and conflict alerts.</li>
                        <li><b>Impact:</b> 4× faster than any other method, error rate ↓66%, 80% clinician adoption, SUS 85+.</li>
                        <li><b>Next:</b> React MVP, explainability dashboard.</li>
                    </ul>
                </section>

                <hr><!-------------------------------------------->

                <!-- Human Cost Section -->
                <section class="section-human-cost">
                    <h2>The Human Cost of Manual Review</h2>
                    <p>Systematic reviews demand endless PDF scrubbing: copy, paste, alt‑tab, over and over. We shadowed Dr. Khan and Dr. Umar as they juggled trial tables and spreadsheets. Midway through the tenth paper, Dr. Khan sighed:</p>

                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="slide2" width="100%" alt="">
                    </figure>

                    <p>Multiply that by a hundred papers, and you see the issue: a process designed for machines, executed by humans.</p>
                    <p>Existing tools like <b>Covidence</b>, <b>Rayyan</b>, or <b>DistillrSR</b> failed on usability. Doctors either abandoned them or hacked their own makeshift systems.</p>

                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="slide3" width="100%" alt="">
                    </figure>
                </section>

                <!-- Challenges Section -->
                <section class="section-challenges">
                    <h2>Challenges Faced</h2>
                    <p>We initially understood high-level issues through informal discussions and workshops, but deeper challenges like specific error rates and AI distrust became clearer through subsequent research. These insights directly informed our detailed design and iterative approach:</p>
                    <ul>
                        <li><b>High Manual Workload:</b> Extracting data from 100+ PDFs per review cycle.</li>
                        <li><b>Error-Prone Process:</b> Copy-paste fatigue led to a 15% transcription error rate.</li>
                        <li><b>Fragmented Tools:</b> Switching between PDF readers, spreadsheets, and search interfaces disrupted workflow.</li>
                        <li><b>AI Skepticism:</b> Lack of transparent sourcing fueled skepticism.</li>
                    </ul>
                </section>

                <hr><!-------------------------------------------->

                <!-- UX Approach Section -->
                <section class="section-ux-approach"><br>

                    <h2>Our UX Approach</h2>
                    <p>Our design process unfolded across iterative phases, each building on user insights and technical feasibility:</p>

                    

                    <h3>Understand & Empathize</h3>
                    <p>We began with informal conversations to understand clinicians' current workflows and deeper pain points. One clinician clearly articulated their hesitation with AI:</p>
                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="slide4" width="100%" alt="">
                    </figure>

                    <h3>Research</h3>
                    <p>To genuinely experience doctors' workflows, we shadowed three researchers through full review sessions, logging issues from version chaos to hidden table rows.</p>
                    <p>Concurrently, we performed heuristic and competitive audits of leading LSR tools (Covidence, Rayyan, DistillrSR), pinpointing gaps in evidence transparency and human–AI collaboration.</p>
                    <figure class="article-figure ">
                        <img class="theme-img" src="" data-name="slide5" width="100%" alt="">
                    </figure>

                    <br>

                    <h3>Brainstorming</h3>
                    <p>We held targeted brainstorming sessions with the core team, applying the MoSCoW framework to categorize and prioritize features into Must‑haves, Should‑haves, Could‑haves, and Wonʼt‑haves.</p>

                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="slide8" width="100%" alt="">
                    </figure>
                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="slide9" width="100%" alt="">
                    </figure>
                    <a href="mid-fidelity-wireframes.html" target="_blank">Link to Idea Board</a><br><br>
                    <p>With rich insights, features prioritized and detailed task-flows, we set a clear vision.</p>
                </section>

                <br><br>

                <!-- Goals & Metrics Section -->
                <section class="section-goals boxed">
                    <h2>Goals & Success Metrics</h2>
                    <p>We aimed to build an intuitive platform automating data extraction using AI/LLM, yet ensuring clear reasoning and easy human supervision. Although stakeholders proposed a cautious 50% automation goal, we set our sights higher.</p>
                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="slide10" width="100%" alt="">
                    </figure>
                </section>

                <br><br>

                <!-- Prototype, Validate, Iterate Section -->
                <section class="section-prototyping">
                    <h2>Prototype, Validate, Iterate</h2>
                    <p>We ran 4 two-week Agile sprints:</p>
                    
                    <h3>Low-Fid Wireframes Roadblocks</h3>
                    <p>Initially, we introduced low-fidelity wireframes to quickly test conceptual workflows. However, clinicians were confused by low-fidelity wireframes filled with empty placeholders—they couldn't visualize how the system would actually function.</p>
                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="slide11" width="100%" alt="">
                    </figure>
                    <p>We observed repeated hesitation during usability sessions. Participants asked for clarification and misunderstood interactions that were only represented as grey boxes or labels.</p>

                    <p><b>Reflection and Pivot:</b> We replaced blank UI elements with realistic, annotated mock data pulled from trial PDFs. This contextual information helped bridge the gap between our conceptual design language and the cliniciansʼ real-world mental model, leading to clearer feedback and deeper engagement.</p>

                    
                    <br>

                    <h3>Insights from Mid-Fid Wireframes</h3>
                    <p>In this stage, mid-fidelity wireframes were presented, but clinicians raised questions regarding system clarity and intuitiveness.</p>

                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="slide13" width="100%" alt="">



                    <p>During the conversations, we learned something revealing: the highest number of doctor retirements occurred when Epic (Electronic Medical Record Management System) was introduced.</p>
                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="slide14" width="100%" alt="">
                    </figure>
                    

                    <p>It became clear that the solution had to feel instantly familiar and require minimal adaptation. This led us to pivot to a spreadsheet-style interface to mirror usersʼ mental models and reduce resistance.</p>


                    <p>From there, we layered on explainability: exploring side-panel interactions that surfaced AI reasoning, dual-model comparisons, and highlighted source excerpts.</p>
                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="slide6" width="100%" alt="">
                    </figure>


                    <br>

                    <h3>Technical Feasibility</h3>
                    <p>The final sprint addressed technical implementation issues, specifically OCR reliability and asynchronous model call latency. Through close collaboration with developers, we validated practical solutions, such as OCR fallbacks, visual loading placeholders, and optimized asynchronous AI model calls, enhancing overall reliability and user experience.</p>
                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="slide16" width="100%" alt="">
                    </figure>

                </section>

                <hr><!-------------------------------------------->

                <!-- Final Solution Section -->
                <section class="section-final-solution"><br>
                    <h2>Final Solution</h2>
                    <ul>
                        <li><b>Smart Suggestion Grid:</b> Inline dual-model AI fills cells; low-confidence fields flagged for review.</li>
                        <li><b>Evidence Panel:</b> Contextual PDF excerpts displayed beside suggestions, ensuring provenance.</li>
                        <li><b>Confidence Alerts:</b> Voting-based system highlights conflicts, involving humans only when needed.</li>
                        <li><b>Continuous Learning Loop:</b> User edits feed back into model retraining for improved future suggestions.</li>
                        <li><b>Audit & Export:</b> Compliance-ready logs and CSV/API export maintain regulatory transparency.</li>
                    </ul>

                    <video loop autoplay muted width="100%"> 
                        <source src="vid/video1.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="slide18" width="100%" alt="">
                    </figure>

                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="slide19" width="100%" alt="">
                    </figure>
                    <video loop autoplay muted width="100%"> 
                        <source src="vid/video2.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><br>
                        The interface is thoughtfully designed to be intuitive and efficient, streamlining the data extraction process with minimal user effort. Users can configure extraction settings simultaneously as files are being uploaded, saving valuable time and eliminating unnecessary steps.
                    </p>
                    <p>
                        Unlike many traditional medical tools, the interface adopts a clean, minimal design. Advanced or infrequently used settings are tucked away behind a toggle, allowing users to stay focused on their core tasks without being overwhelmed by clutter or irrelevant options.
                    </p>
                    <video loop autoplay muted width="100%"> 
                        <source src="vid/video3.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><br>
                        If a user decides to add a new column, it's as simple as clicking the "+" button. The user could either type out what they want to extract or select from a list of common extraction types. The system will then automatically generate the necessary prompts for the AI model, streamlining the process and ensuring accuracy.
                    </p>
                    <video loop autoplay muted width="100%"> 
                        <source src="vid/video4.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p><br>
                        The system highlights cells with low confidence scores, allowing users to prioritize their review efforts. This feature is particularly useful when dealing with large datasets, as it helps users quickly identify areas that require their attention.<br><br>                        
                    </p>
                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="slide15" width="100%" alt="">
                    </figure>
                    <video loop autoplay muted width="100%"> 
                        <source src="vid/video5.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p>
                        To quickly reference the original data, users can hover over a cell to view the corresponding PDF excerpt. This feature is especially helpful when users need to verify the accuracy of the extracted information or understand the context in which it was presented. <br><br>

                        The system also provides a side panel that displays the AI's reasoning for its suggestions. This transparency helps users understand how the AI arrived at its conclusions and fosters trust in the system. 
                    </p>


                </section>

                <hr><!-------------------------------------------->

                <!-- Impact & Metrics Section -->
                <section class="section-impact-metrics">
                    <h2>Impact & Metrics</h2>
                    <ul>
                        <li><b>Extraction Speed:</b> 4× faster than typical workflows involving ChatGPT or other AI tools. Reduced the average process from 2 months to less than a week.</li>
                        <li><b>Error Rate:</b> Reduced from 15% (manual) to 2% (pilot).</li>
                        <li><b>Adoption:</b> 80% of clinicians found the tool highly usable and expressed a strong likelihood of incorporating it into their workflow.</li>
                        <li><b>Usability:</b> System Usability Scale score of 85+, indicating excellent usability.</li>
                    </ul>
                </section>

                <hr><!-------------------------------------------->
                <!-- Reflections Section -->
                <section class="section-reflections">
                    <h2>Reflections</h2>
                    <p>Through this project, we learned critical lessons:</p>
                    <ul>
                        <li><strong>Adaptability:</strong> It's easier to adapt to user styles than expect users to learn new systems.</li>
                        <li><strong>Transparency:</strong> Clear evidence and explanations are crucial for AI acceptance.</li>
                        <li><strong>Early Technical Alignment:</strong> Collaborating with developers early helped mitigate late-stage surprises.</li>
                        <li><strong>Balance:</strong> Users preferred augmenting their judgment rather than full automation.</li>
                        <li><strong>Familiarity:</strong> Leveraging familiar mental models (e.g., spreadsheets) greatly reduced user resistance.</li>
                    </ul>
                </section>

                    <figure class="article-figure">
                        <img class="theme-img" src="" data-name="tldr slide11" width="100%" alt="">
                    </figure>
                
                <!-- Learnings Section -->
                <section class="section-detailed-learnings">
                    <h2>Learnings</h2>
                    <ul>
                        <li><b>Know your client:</b> Doctors don’t design. Wireframes needed to feel real to get useful feedback. It’s easier to adapt to their context than expect them to adapt to ours.</li>
                        <li><b>Trust comes from transparency:</b> The side panel did more than explain—it turned AI into a collaborator.</li>
                        <li><b>Embrace constraints early:</b> Parsing issues and latency could have derailed the project. Early collaboration with engineers helped us design around limitations, not despite them.</li>
                        <li><b>Doctors value control over speed:</b> They didn’t want full automation—they wanted AI to augment their judgment, not override it.</li>
                        <li><b>Familiarity is your Trojan Horse:</b> By mimicking Excel and Airtable, we lowered the learning curve and framed AI as just a smarter cell.</li>
                    </ul>
                </section>
              

                <footer>
                    <br><br><br>
                    <hr>
                    <div class="footer-container">
                    <a href="#top" class="hyp-p">back to top ↑</a>
                    <!-- <a href="LSR.html" class="hyp-p">Easter Egg? </a>-->
                    </div>
                </footer>
            
            </article>
            
        </div>


        <script src="script.js"></script>
    </body>
</html>








<!--Templates-->

<!--

<p > 
    At the moment, Youtube Music holds under 10% of the streaming market. <a class="hyp-p" href="https://evoca.tv/streaming-service-market-share/#:~:text=Spotify 31.7,Deezer 1.3">(source) ↗</a>
</p>